{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLEassignment1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2S8I2ny-ovS"
      },
      "source": [
        "# NLE Assignment 1: Books vs DVDs\n",
        "\n",
        "In this assignment, you will be investigating NLP methods for distinguishing reviews written about books from reviews written about DVDs.\n",
        "\n",
        "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
        "\n",
        "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
        "\n",
        "Marking guidelines are provided as a separate document.\n",
        "\n",
        "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gXQAZas-l9c"
      },
      "source": [
        "candidateno = 215816 #this MUST be updated to your candidate number so that you get a unique data sample\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXshmwtaBTGm",
        "outputId": "da9ccd47-a475-4ec5-aaa5-1bb8a4bc2895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#set up drives for resources.  Change the path as necessary\n",
        "\n",
        "from google.colab import drive\n",
        "#mount google drive\n",
        "drive.mount('/content/drive/')\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/NLE Notebooks/resources/')\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk8JTP88A8vs",
        "outputId": "c042c459-46db-461e-fc78-d5a00d38d313",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#do not change the code in this cell\n",
        "#preliminary imports\n",
        "\n",
        "#for setting up training and testing data\n",
        "from sussex_nltk.corpus_readers import AmazonReviewCorpusReader\n",
        "import random\n",
        "\n",
        "#set up nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#useful other tools\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "from itertools import zip_longest\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHBkzAccCVaZ"
      },
      "source": [
        "#do not change the code in this cell\n",
        "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
        "    \"\"\"\n",
        "    Given corpus generator and ratio:\n",
        "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
        "\n",
        "    :param data: A corpus generator.\n",
        "    :param ratio: The proportion of training documents (default 0.7)\n",
        "    :return: a pair (tuple) of lists where the first element of the \n",
        "            pair is a list of the training data and the second is a list of the test data.\n",
        "    \"\"\"\n",
        "    \n",
        "    data = list(data)  \n",
        "    n = len(data)  \n",
        "    train_indices = random.sample(range(n), int(n * ratio))          \n",
        "    test_indices = list(set(range(n)) - set(train_indices))    \n",
        "    train = [data[i] for i in train_indices]           \n",
        "    test = [data[i] for i in test_indices]             \n",
        "    return (train, test)                       \n",
        " \n",
        "\n",
        "def feature_extract(review):\n",
        "    \"\"\"\n",
        "    Generate a feature representation for a review\n",
        "    :param review: AmazonReview object\n",
        "    :return: dictionary of Boolean features\n",
        "    \"\"\"\n",
        "    return {word:True for word in review.words()}\n",
        "\n",
        "def get_training_test_data(categories=('book','dvd'),ratio=0.7,seed=candidateno):\n",
        "    \"\"\"\n",
        "    Get training and test data for a given pair of categories and ratio, pre-formatted for use with NB classifier\n",
        "    :param category: pair of categories of review corpus, two from [\"kitchen, \"dvd, \"book\", \"electronics\"]\n",
        "    :param ratio: proportion of data to use as training data\n",
        "    :return: pair of lists \n",
        "    \"\"\"\n",
        "    random.seed(candidateno)\n",
        "\n",
        "    train_data=[]\n",
        "    test_data=[]\n",
        "    for category in categories:\n",
        "      reader=AmazonReviewCorpusReader().category(category)    \n",
        "      train, test = split_data(reader.documents(),ratio=ratio)\n",
        "   \n",
        "      train_data+=[(feature_extract(review),category)for review in train]\n",
        "      test_data+=[(feature_extract(review),category)for review in test]\n",
        "    random.shuffle(train_data)\n",
        "    random.shuffle(test_data)\n",
        "\n",
        "    return train_data,test_data"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3LWwBYICPP"
      },
      "source": [
        "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJLegkdPFUJA",
        "outputId": "ab4486bc-bbe3-420f-80b4-e954c1b08ef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#do not change the code in this cell\n",
        "training_data,testing_data=get_training_test_data()\n",
        "print(\"The amount of training data is {}\".format(len(training_data)))\n",
        "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
        "print(\"The representation of a single data item is below\")\n",
        "print(training_data[0])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The amount of training data is 6526\n",
            "The amount of testing data is 2799\n",
            "The representation of a single data item is below\n",
            "({'We': True, \"'ll\": True, 'keep': True, 'this': True, 'one': True, 'simple': True, ':': True, \"-'Aliens\": True, \"'\": True, 'is': True, 'the': True, 'greatest': True, 'action': True, 'movie': True, 'of': True, 'all-time': True, ',': True, 'and': True, 'it': True, \"'s\": True, 'not': True, 'a': True, 'bad': True, 'horror': True, 'either': True, '.': True, 'It': True, 'more': True, 'unremittingly': True, 'intense': True, 'movies': True, 'The': True, 'final': True, 'third': True, 'just': True, 'relentless': True, 'even': True, 'various': True, 'slow': True, 'parts': True, 'have': True, 'an': True, 'undeniable': True, 'electricity': True, 'to': True, 'them': True, 'after': True, 'like': True, '10': True, 'viewings': True, 'on': True, 'my': True, 'part': True, 'absolute': True, 'masterpiece': True, 'practical': True, 'special': True, 'effects': True, 'aliens': True, 'themselves': True, 'set-design': True, 'props': True, 'costumes': True, 'etc': True, 'All': True, 'brilliant': True, 'combination': True, 'all': True, 'disparate': True, 'elements': True, 'may': True, 'be': True, 'completely': True, 'seamless': True, 'but': True, 'surprisingly': True, 'close': True, 'helluva': True, 'lot': True, 'convincing': True, 'than': True, 'total': True, 'CGI': True, 'films': True, 'inflicted': True, 'us': True, 'so': True, 'much': True, 'nowadays': True, '(': True, 'I': True, \"'m\": True, 'those': True, 'knee-jerk': True, 'opposed': True, 'people': True, 'do': True, \"n't\": True, 'think': True, 'you': True, 'should': True, 'use': True, 'when': True, 'can': True, 'done': True, 'well': True, 'with': True, 'which': True, 'naturally': True, 'modern': True, 'practice': True, 'using': True, 'at': True, 'times': True, 'for': True, 'things': True, 'no': True, 'apparent': True, 'reason': True, ')': True, '-It': True, 'got': True, 'some': True, 'atypically': True, 'memorable': True, 'good': True, 'characters': True, 'acting': True, 'action/sci-fi/horror': True, 'Yeah': True, 'many': True, 'are': True, 'kinda': True, 'cliched': True, 'they': True, \"'re\": True, 'well-done': True, 'cliches': True, 'anyway': True, 'Weaver': True, 'really': True, 'comes': True, 'into': True, 'her': True, 'own': True, 'as': True, 'Ripley': True, 'making': True, 'quite': True, 'bit': True, 'interesting': True, 'likable': True, 'she': True, 'was': True, 'first': True, 'time': True, 'around': True, 'while': True, 'still': True, 'basically': True, 'seeming': True, 'same': True, 'person': True, 'Furthermore': True, 'Michael': True, 'Biehn': True, 'Lance': True, 'Henricksen': True, 'give': True, 'their': True, 'definitive': True, 'performances': True, '-If': True, 'or': True, 'another': True, \"'ve\": True, 'never': True, 'actually': True, 'seen': True, \"'Aliens\": True, 'would': True, 'recommend': True, 'watch': True, 'theatrical': True, 'cut': True, 'Once': True, 'already': True, 'know': True, 'overall': True, 'plot': True, 'Director': True, 'Cut': True, 'better': True, 'stuff': True, 'that': True, 'added': True, 'in': True, 'cool': True, 'tips': True, 'its': True, 'hand': True, 'little': True, 'too': True, 'early': True, 'best': True, 'away': True, 'info': True, 'Not': True, 'matters': True, 'way': True, 'This': True, 'awesome': True, 'Watch': True, 'lame': True, 'forever': True, 'Grade': True}, 'dvd')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f6h0ON9I4NT"
      },
      "source": [
        "1) Use your training data to find\n",
        "a) the top 20 words which occur more frequently in book reviews than in dvd reviews\n",
        "b) the top 20 words which occur more frequently in dvd reviews than book reviews\n",
        "Discuss what pre-processing techniques you have applied (or not applied) in answering this question, and why. [20%]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wJ-ajVeFYjr",
        "outputId": "4a55158e-0971-436a-abf5-1d9f153d3054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.probability import FreqDist\n",
        "from functools import reduce\n",
        "\n",
        "def get_book_dvd_training_data(training_data):\n",
        "  \"\"\"\n",
        "    Get book and dvd review training data\n",
        "    :param training_data: A nested list of dvd and book review data\n",
        "    :return: pair of lists where the first element of the pair is a list of the book training data and the second is a list of the dvd training data.\n",
        "    \"\"\"\n",
        "  book_train = []\n",
        "  dvd_train = []\n",
        "  for (docs,label) in training_data:\n",
        "    if 'book' in label:\n",
        "      book_train +=docs.keys()\n",
        "    else:\n",
        "      dvd_train +=docs.keys()\n",
        "\n",
        "  return book_train,dvd_train\n",
        "\n",
        "def frequent_words_in_book_dvd(book_train,dvd_train):\n",
        "  \"\"\"\n",
        "    Get the words and the number of times certain words occur from the book training data and dvd training data\n",
        "    :param book_train: A list of book review data\n",
        "    :param dvd_train: A list of dvd review data\n",
        "    :return: pair of dictionaries where the first element is a dictionary, where the keys are words occurring in book reviews and the values are the number of times a certain word occurs,\n",
        "             and the second is a dictionary, where the keys are words occurring in DVD reviews and the values are the number of times a certain word occurs.\n",
        "    \"\"\"\n",
        "  book_train,dvd_train = get_book_dvd_training_data(training_data)\n",
        "  wl = WordNetLemmatizer()\n",
        "  lemma_book = [wl.lemmatize(word) for word in book_train]                #Break a word down into it's root word\n",
        "  lemma_dvd = [wl.lemmatize(word) for word in dvd_train]\n",
        "  lower_book = [word.lower() for word in lemma_book]                      #Convert all words to lower case\n",
        "  lower_dvd =  [word.lower() for word in lemma_dvd]\n",
        "  filter_book = [word for word in lower_book if word.isalpha() and word not in stop]    #Filter the words which solely contain characters and remove the stopwords(the,a,and...)\n",
        "  filter_dvd = [word for word in lower_dvd if word.isalpha() and word not in stop]\n",
        "  book_frequ = FreqDist(filter_book)\n",
        "  dvd_frequ = FreqDist(filter_dvd)\n",
        "  return book_frequ,dvd_frequ"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOCCcZDOKirm"
      },
      "source": [
        "stop = stopwords.words('english')\n",
        "book_train,dvd_train = get_book_dvd_training_data(training_data)\n",
        "book_freqdist,dvd_freqdist = frequent_words_in_book_dvd(book_train,dvd_train)\n",
        "\n",
        "def top_words_book_dvd(top_words_class_A_compared_to_class_B,class_B,top):\n",
        "  \"\"\"\n",
        "    Get the most frequent words from the book training data and dvd training data\n",
        "    :param dvd_freqdist: A dicitonary of dvd review data, where the keys are words and the values are the number of times those words occur\n",
        "    :param book_freqdist: A dicitonary of book review data, where the keys are words and the values are the number of times those words occur\n",
        "    :param top: The number of top words occuring in both, dvd and book reviews\n",
        "    :return: A list of the top words, occuring in book reviews or dvd reviews (depends which parameter is entered first)\n",
        "    \"\"\"\n",
        "  difference = [(w,f-class_B.get(w,0)) for (w,f) in top_words_class_A_compared_to_class_B.most_common()]   #Get the most common words in class A (e.g book) reviews, and compare how often these occur in class B (dvd)\n",
        "  sortediff = sorted(difference,key=lambda pair:pair[1],reverse=True) \n",
        "  top_words = [w for (w,f) in sortediff]                         \n",
        "  return top_words[:top]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWUMe5beKtgz",
        "outputId": "8826d826-f7d2-4447-f915-91edae7960dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "top_dvd=top_words_book_dvd(dvd_freqdist,book_freqdist,20)\n",
        "print(\"These are the most frequent words in dvd reviews\")\n",
        "print(top_dvd)\n",
        "\n",
        "top_book=top_words_book_dvd(book_freqdist,dvd_freqdist,20)\n",
        "print(\"These are the most frequent words in book reviews\")\n",
        "print(top_book)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These are the most frequent words in dvd reviews\n",
            "['movie', 'film', 'dvd', 'watch', 'one', 'scene', 'great', 'wa', 'see', 'like', 'show', 'get', 'love', 'time', 'good', 'watching', 'seen', 'performance', 'actor', 'ha']\n",
            "These are the most frequent words in book reviews\n",
            "['book', 'read', 'author', 'reading', 'reader', 'page', 'writing', 'novel', 'written', 'chapter', 'information', 'example', 'business', 'history', 'recipe', 'research', 'topic', 'idea', 'description', 'subject']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZmZ3u2_mIBh"
      },
      "source": [
        "To find the 20 most frequent words in dvd and book reviews, we must first get all of the tokens which occur in both dvd and book reviews from the training data.\n",
        "\n",
        "**Note** that the training data is represented as a nested list(document,label) where in the document(represented as a dicitonary) every key is a token; the review data has been **tokenized** (a pre-processing technique, where the tokens are separated by whitespace in the review string, and have been imputed into a list), followed by the value true. Label is the class a document belongs to, it is either dvd or book.\n",
        "\n",
        "To separate the book and dvd review data from the training data we run a loop around the entire training data, and separate it into a list of words occuring in book reviews and a list of words occuring in dvd reviews. To acquire the words, we use the label from the training data to categorize the words into different classes (dvd or book).\n",
        "\n",
        "Then, we call a method called FreqDist to get how often do the tokens occur in each of our classes.\n",
        "\n",
        "Finally we get the tokens which occur more frequently in one class than the other, and return the top 20 words occuring in each class.\n",
        "\n",
        "The pre processing techniques were used when putting all of the words from the reviews into lists. The techniques chosen were **case normalisation**, because by setting all words to lower case, the frequency of certain words occuring increases,**number removal** because we want to get the most frequent words, not numbers and **punctuation and stopword removal** because they occur very frequently in all documents, which doesn't help us in finding which words occur more in one document or the other. **Lemmatisation** was also used, because it increases the frequency of a particular word (it removes the affixes, number, gender etc.). **Stemming was not used**, as it can produce errors of commission, e.g organization does not derive to organ, which is what stemming would do. **Sentence segmentation was not used**, as when the training data was created, all of the words in every review where split into single tokens instead of sentences.Also, **Number normalisation was not used**, as we are only interested in the most frequent words, not numbers (we remove the numbers, see number removal). In addition to that, **alphabetical ordering** was not used either, as we are not interested in ordering the words from the reviews alphabetically."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TApOQE6vND20"
      },
      "source": [
        "2) Design, build and test a word list classifier to classify reviews as being from the book domain or from the dvd domain.  Make sure you discuss 1) how you decide the lengths and contents of the word lists and ii) accuracy, precision and recall of your final classifier.[30%]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BThDMrcmODJy"
      },
      "source": [
        "from nltk.classify.api import ClassifierI  \n",
        "import random\n",
        "# Classifier class. This class is used to classify documents into book reviews and dvd reviews\n",
        "#Initialise the class, with the most frequent words in book and dvd reviews\n",
        "    #:param self: Represents instance of the class\n",
        "    #:param dvd: A list of the most frequent words in dvd reviews\n",
        "    #:param book: A list of the most frequent words in book reviews\n",
        "class Simple_classifier_dvd_book(ClassifierI):\n",
        "  def __init__(self,dvd,book):\n",
        "    self._dvd = dvd\n",
        "    self._book = book\n",
        "\n",
        "  def classify(self, words):\n",
        "    \"\"\"\n",
        "    Classifies if a list of words belongs to the book reviews or dvd reviews\n",
        "    :param self: Represents instance of the class\n",
        "    :param words: A list of strings\n",
        "    :return: If the words that appear in the list also appear in the most frequent words in dvd reviews, return \"dvd\"\n",
        "             else if the words that appear in the list also appear in the most frequent words in book reviews, return \"book\".\n",
        "             If the list does not belong to neither book or dvd reviews, return \"book\".\n",
        "    \"\"\"\n",
        "    score = 0\n",
        "    for word in words:\n",
        "      if word in self._book:\n",
        "        score = score + 1\n",
        "      if word in self._dvd:\n",
        "        score = score-1\n",
        "    if score == 0:                    #If classifier doesn't know to which class a review belongs to, it takes a guess\n",
        "      score = random.choice((-1,1))\n",
        "    return \"dvd\" if score < 0 else \"book\"   \n",
        "\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCjcal0H7yQI"
      },
      "source": [
        "#An extension of the Classifier_dvd_book. Here we implement a method for the classifier to train on some training data.\n",
        "#The size of the training data is what the user desires.\n",
        "#Initialises the class with an integer\n",
        "    #:param self: Represents instance of the class\n",
        "    #:param k: The number of reviews the user want to input\n",
        "class BinaryClassifier(Simple_classifier_dvd_book):\n",
        "\n",
        "  def __init__(self,k):\n",
        "    self._k = k\n",
        "\n",
        "  def train(self,training_data):\n",
        "    \"\"\"\n",
        "    Trains the classifier with a certain amount of training data (what the user specified)\n",
        "    :param self: Represents instance of the class\n",
        "    :param training_data: A list of dvd and book review data\n",
        "    \"\"\"\n",
        "    book_train,dvd_train = get_book_dvd_training_data(training_data)\n",
        "    book_freqdist,dvd_freqdist = frequent_words_in_book_dvd(book_train,dvd_train)\n",
        "    self._dvd = top_words_book_dvd(dvd_freqdist,book_freqdist,self._k)\n",
        "    self._book = top_words_book_dvd(book_freqdist,dvd_freqdist,self._k)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyHbdCc97yYD"
      },
      "source": [
        "def classifier_accuracy(classifier,testing_data):\n",
        "  \"\"\"\n",
        "    Calculates how accurate is the classifier when labelling if a review belongs to a dvd review or book review\n",
        "    :param classifier: Either a BinaryClassifier from the Binary Classifier class or an Naïve Bayes Classifer from the NBclass\n",
        "    :param testing_data: A list of dvd and book review data\n",
        "    \"\"\"\n",
        "  acc = 0\n",
        "  for (doc,label) in testing_data:\n",
        "    if classifier.classify(doc) in label:\n",
        "      acc+=1\n",
        "    else:\n",
        "      0\n",
        "  return acc / (len(testing_data) + 0.0) \n",
        "\n",
        "def get_predictions(classifier):\n",
        "  \"\"\"\n",
        "    Get what the classifier has predicted of the review testing data\n",
        "    :param classifier: Either a BinaryClassifier from the Binary Classifier class or an Naïve Bayes Classifer from the NBclass\n",
        "    \"\"\"\n",
        "  pred = []\n",
        "  for (doc,label) in testing_data:\n",
        "    pred += classifier.classify(doc).split()\n",
        "  return pred\n",
        "\n",
        "def get_goldstandards(classifier):\n",
        "  \"\"\"\n",
        "    Get what the actual label (book or dvd) from the testing data\n",
        "    :param classifier: Either a BinaryClassifier from the Binary Classifier class or an Naïve Bayes Classifer from the NBclass\n",
        "    \"\"\"\n",
        "  true = []\n",
        "  for (doc,label) in testing_data:\n",
        "    true += label.split()\n",
        "  return true"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEHvGIPn55Kr"
      },
      "source": [
        "#Set up a confusion matrix, to check what the True positives, False positives, False negatives and True Negatives for the predicitions and goalstandards\n",
        "#Initialise the class, with the predicitons, goalstandards and classes of the reviews\n",
        "    #:param self: Represents instance of the class\n",
        "    #:param predicitions: A list of the classes of reviews predicited by the classifier\n",
        "    #:param goldstandards: A list of the classes of reviews, which are 100% accurate\n",
        "    #:param classes: A pair of strings, specifying the classes \"book\" and \"dvd\"\n",
        "class ConfusionMatrix:\n",
        "    def __init__(self,predictions,goldstandard,classes=(\"book\",\"dvd\")):\n",
        "        (self.c1,self.c2)=classes\n",
        "        self.TP=0\n",
        "        self.FP=0\n",
        "        self.FN=0\n",
        "        self.TN=0\n",
        "        for p,g in zip(predictions,goldstandard):\n",
        "            if g==self.c1:\n",
        "                if p==self.c1:\n",
        "                    self.TP+=1\n",
        "                else:\n",
        "                    self.FN+=1\n",
        "            \n",
        "            elif p==self.c1:\n",
        "                self.FP+=1\n",
        "            else:\n",
        "                self.TN+=1\n",
        "    \n",
        "    def precision(self):\n",
        "      \"\"\"\n",
        "      Calculates how precise was the classifier when predicting the class\n",
        "    :param self: Represents instance of the class\n",
        "    \"\"\"\n",
        "      p=0\n",
        "      p = self.TP/(self.TP+self.FP)\n",
        "      return p\n",
        "    \n",
        "    def recall(self):\n",
        "      \"\"\"\n",
        "      Calculates the recall of the classifier\n",
        "    :param self: Represents instance of the class\n",
        "    \"\"\"\n",
        "      r=0\n",
        "      r = self.TP/(self.TP+self.FN)\n",
        "      return r\n",
        "\n",
        "    def final_score(self):\n",
        "      \"\"\"\n",
        "      Calculates the final score of the classifier\n",
        "    :param self: Represents instance of the class\n",
        "    \"\"\"\n",
        "      f1 = 0\n",
        "      f1 = 2*(self.TP/(self.TP+self.FP))*(self.TP/(self.TP+self.FN))/(self.TP/(self.TP+self.FP)+self.TP/(self.TP+self.FN))\n",
        "      return f1"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAXllN2_Adoa",
        "outputId": "748bcde4-41d6-4c68-aaaf-5eb6f5886ba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dvd_book_classifier = BinaryClassifier(20)\n",
        "dvd_book_classifier.train(training_data)\n",
        "print(\"This is the classifier's accuracy: {}\".format(classifier_accuracy(dvd_book_classifier,testing_data)))\n",
        "confusion = ConfusionMatrix(get_predictions(dvd_book_classifier),get_goldstandards(dvd_book_classifier))\n",
        "print(\"This is the classifier's precision: {}\".format(confusion.precision()))\n",
        "print(\"This is the classifier's recall: {}\".format(confusion.recall()))\n",
        "print(\"This is the classifier's final score: {}\".format(confusion.final_score()))\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the classifier's accuracy: 0.8152911754197928\n",
            "This is the classifier's precision: 0.8738317757009346\n",
            "This is the classifier's recall: 0.6498696785403997\n",
            "This is the classifier's final score: 0.7453911310413553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdcQHkqJ_cdS"
      },
      "source": [
        "The classifier has been designed in the following way: The Simple_classifier_dvd_book class, is not trained on data, it just asks for a word list of dvd and book reviews (from exercise 1 input top book and dvd review words) and then classifies a list of words into the dvd class, if the list contains words from the top dvd review list, otherwise it will classify it in the book class if the list contains words from the top book review list. If the list does not contain words from neither of the classes, than the classifier classifies the list into a class at random.\n",
        "The Binary class classifier, is an extension of the Simple_classifier_dvd_book, which trains on a certain amount of the training data (the user inputs a number, which is the amount of training data that the classifier uses), or in other words, it gets the most common n words, n being the number inputed by the user, from book reviews and dvd reviews.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "For deciding the content and length of the wordlist. The user, inputs the top words occuring in book and dvd reviews, back from excercise 1, and from those list, the user decides how many words from the most frequent words in book and dvd reviews should be included when classifying documents, e.g if the user inputs 20, then the wordlist will contain the top 20 words ocurring in dvd reviews and book reviews. **Note** we decide it is best to use around 20 words for the wordlist, because if there are too many words, like 100, the classifier will have a hard time classifying documents, as the word list for most frequent words in dvd reviews and book reviews will have words which occur in both reviews.\n",
        "\n",
        "Discussing the results of our classifier, we can see that it is quite accurate (correct predictions over the length of the testing data) and precise (the proportion of a class (in this case \"book\") predictions that are correct). But the recall is about 65% (is the proportion of actually class (in this case \"book\") documents that are predicted correctly), meaning that to improve it, we have to reduce the number of false negatives (Document labeled to the class we want, but predicted as being of the other class). Still, our final score 75% which is quite good, because it means that are precision and recall is actually quite high."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIS9UpmJNEAp"
      },
      "source": [
        "3) Compare the performance of your word list classifier with a Naive Bayes classifier (e.g., from NLTK).  Make sure you discuss the results. [20%]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EdIxRqhY7mn"
      },
      "source": [
        "#Reason I havent imported the Naïve Bayes classifier from utils, is because the assigment specifies that our own code should be included in the notebook rather than imported from elsewhere\n",
        "#This code is not commented, as it is imported from the utils file, nothing has been changed except for the labels, from positive to book and negative to dvd\n",
        "\n",
        "import math\n",
        "class NBClassifier(ClassifierI):\n",
        "    \n",
        "    def __init__(self):\n",
        "        self._labels=[\"dvd\",\"book\"]\n",
        "        pass\n",
        "    \n",
        "    def labels(self): \n",
        "        return self._labels\n",
        "    \n",
        "    def set_known_vocabulary(self,training_data):\n",
        "        known=[]\n",
        "        for doc,label in training_data:\n",
        "            known+=list(doc.keys())\n",
        "        self.known= set(known)\n",
        "    \n",
        "    def set_priors(self,training_data):\n",
        "        priors={}\n",
        "        for (doc,label) in training_data:\n",
        "            priors[label]=priors.get(label,0)+1\n",
        "        total=sum(priors.values())\n",
        "        for key,value in priors.items():\n",
        "            priors[key]=value/total\n",
        "        self.priors=priors\n",
        "        \n",
        "    def set_cond_probs(self,training_data):\n",
        "        conds={}\n",
        "        for(doc,label) in training_data:\n",
        "            classcond=conds.get(label,{})\n",
        "            for word in doc.keys():\n",
        "                classcond[word]=classcond.get(word,0)+1\n",
        "        \n",
        "            conds[label]=classcond\n",
        "    \n",
        "        for label, classcond in conds.items():\n",
        "            for word in self.known:\n",
        "        \n",
        "                classcond[word]=classcond.get(word,0)+1\n",
        "            conds[label]=classcond\n",
        "            \n",
        "        for label,dist in conds.items():\n",
        "            total=sum(dist.values())\n",
        "            conds[label]={key:value/total for (key,value) in dist.items()}\n",
        "        \n",
        "        self.conds=conds\n",
        "    \n",
        "    def train(self,training_data):\n",
        "        self.set_known_vocabulary(training_data)\n",
        "        self.set_priors(training_data)\n",
        "        self.set_cond_probs(training_data)\n",
        "    \n",
        "    def classify(self,doc):\n",
        "        doc_probs={key:math.log(value) for (key,value) in self.priors.items()}\n",
        "        for word in doc.keys():\n",
        "            if word in self.known:\n",
        "                doc_probs={classlabel:sofar+math.log(self.conds[classlabel].get(word,0)) for (classlabel,sofar) in doc_probs.items()}\n",
        "\n",
        "        highprob=max(doc_probs.values())\n",
        "        classes=[c for c in doc_probs.keys() if doc_probs[c]==highprob]\n",
        "        return random.choice(classes)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YUiYKyrOSA0"
      },
      "source": [
        "nb = NBClassifier()\n",
        "nb.train(training_data)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5OkeMGN7zMY",
        "outputId": "aa47be01-6481-4f51-a03b-a5991a9de8fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nbc = ConfusionMatrix(get_predictions(nb),get_goldstandards(nb))\n",
        "\n",
        "print(\"This is the NBclassifier's accuracy: {}\".format(classifier_accuracy(nb,testing_data)))\n",
        "print(\"This is the NBclassifier's recall: {}\".format(nbc.recall()))\n",
        "print(\"This is the NBclassifier's precision: {}\".format(nbc.precision()))\n",
        "print(\"This is the NBclassifier's final score: {}\".format(nbc.final_score()))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the NBclassifier's accuracy: 0.9389067524115756\n",
            "This is the NBclassifier's recall: 0.8922675933970461\n",
            "This is the NBclassifier's precision: 0.9562383612662942\n",
            "This is the NBclassifier's final score: 0.9231460674157304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgFqu57B39wu"
      },
      "source": [
        "The Naïve Bayes classifier, uses all of the training data, that is to say, it gets all of the tokens from the training data, unlike our Binary classifier, which only gets a certain amount of training data which is specified by the user. From that training data, the Naïve Bayes classifier sets up class priors, which sets up the probability of a document being in either class dvd reviews or book reviews, it also sets up the conditional probabilities, which are the probabilities of a certain word ocurring in a certain class document, e.g the probability of seeing book in a book reviews document.\n",
        "\n",
        "Discussing the results of our Naïve Bayes classifier. We can see it has 93% accuracy, meaning it almost always predicts the label correctly. It has a 89% recall, the proportion of actually class (in this case \"book\") documents that are predicted correctly and a 95% precision the proportion of a class (in this case \"book\") predictions that are correct. As the Naïve Bayes classifier has a high precision and recall, we can imply that the final score will also be high; 92%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGDXaVDqOSfY"
      },
      "source": [
        "4) Design and carry out an experiment into the impact of the amount of training data on each of these classifiers.  Make sure you describe design decisions in your experiment, include a graph of your results and discuss your conclusions. [30%] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWUAkfBQw6O-",
        "outputId": "7629650d-7a64-4d9b-fa60-4d4b2fe5e4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from random import sample\n",
        "samples = [6, 10, 50, 100, 200, 400, 600, 700]\n",
        "\n",
        "classifiers={\"Binary classifier\":BinaryClassifier(20),\n",
        "             \"Naïve Bayes classifier\": NBClassifier()}\n",
        "\n",
        "use=[\"Binary classifier\",\"Naïve Bayes classifier\"]\n",
        "\n",
        "results = []\n",
        "sample_size = random.sample(samples,4)\n",
        "for s in sample_size:\n",
        "  for name,classifier in classifiers.items():\n",
        "    if name in use:\n",
        "      classifier.train(training_data[:s])\n",
        "      accuracy=classifier_accuracy(classifier,testing_data)\n",
        "      cn = ConfusionMatrix(get_predictions(classifier),get_goldstandards(classifier))\n",
        "      precision = cn.precision()\n",
        "      recall = cn.recall()\n",
        "      print(\"The accuracy of {} is {} for training data size {}\".format(name,round(accuracy,2),s))\n",
        "      print(\"The precision of {} is {} for training data size {}\".format(name,round(precision,2),s))\n",
        "      print(\"The recall of {} is {} for training data size {} \\n\".format(name,round(recall,2),s))\n",
        "      results.append((name+\" with size of training data \"+str(s),round(accuracy,2),round(precision,2),round(recall,2)))\n",
        "             \n",
        "df = pd.DataFrame(results,columns= [\"Name of classifier and amount of training data\",\"Accuracy\",\"Precision\",\"Recall\"])\n",
        "display(df)\n",
        "ax = df.plot.bar(title=\"Experimental Results on the amount of training data in classifiers\",legend=False,x=0)\n",
        "ax.set_ylabel(\"Percentage\")\n",
        "ax.set_xlabel(\"Classifiers\")\n",
        "ax.set_ylim(0,1.0)\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of Binary classifier is 0.82 for training data size 6\n",
            "The precision of Binary classifier is 0.87 for training data size 6\n",
            "The recall of Binary classifier is 0.64 for training data size 6 \n",
            "\n",
            "The accuracy of Naïve Bayes classifier is 0.59 for training data size 6\n",
            "The precision of Naïve Bayes classifier is 1.0 for training data size 6\n",
            "The recall of Naïve Bayes classifier is 0.0 for training data size 6 \n",
            "\n",
            "The accuracy of Binary classifier is 0.81 for training data size 10\n",
            "The precision of Binary classifier is 0.87 for training data size 10\n",
            "The recall of Binary classifier is 0.64 for training data size 10 \n",
            "\n",
            "The accuracy of Naïve Bayes classifier is 0.59 for training data size 10\n",
            "The precision of Naïve Bayes classifier is 0.91 for training data size 10\n",
            "The recall of Naïve Bayes classifier is 0.01 for training data size 10 \n",
            "\n",
            "The accuracy of Binary classifier is 0.82 for training data size 100\n",
            "The precision of Binary classifier is 0.88 for training data size 100\n",
            "The recall of Binary classifier is 0.65 for training data size 100 \n",
            "\n",
            "The accuracy of Naïve Bayes classifier is 0.66 for training data size 100\n",
            "The precision of Naïve Bayes classifier is 0.99 for training data size 100\n",
            "The recall of Naïve Bayes classifier is 0.16 for training data size 100 \n",
            "\n",
            "The accuracy of Binary classifier is 0.82 for training data size 400\n",
            "The precision of Binary classifier is 0.88 for training data size 400\n",
            "The recall of Binary classifier is 0.63 for training data size 400 \n",
            "\n",
            "The accuracy of Naïve Bayes classifier is 0.9 for training data size 400\n",
            "The precision of Naïve Bayes classifier is 0.94 for training data size 400\n",
            "The recall of Naïve Bayes classifier is 0.8 for training data size 400 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name of classifier and amount of training data</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Binary classifier with size of training data 6</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naïve Bayes classifier with size of training d...</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Binary classifier with size of training data 10</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Naïve Bayes classifier with size of training d...</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Binary classifier with size of training data 100</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Naïve Bayes classifier with size of training d...</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Binary classifier with size of training data 400</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Naïve Bayes classifier with size of training d...</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Name of classifier and amount of training data  ...  Recall\n",
              "0     Binary classifier with size of training data 6  ...    0.64\n",
              "1  Naïve Bayes classifier with size of training d...  ...    0.00\n",
              "2    Binary classifier with size of training data 10  ...    0.64\n",
              "3  Naïve Bayes classifier with size of training d...  ...    0.01\n",
              "4   Binary classifier with size of training data 100  ...    0.65\n",
              "5  Naïve Bayes classifier with size of training d...  ...    0.16\n",
              "6   Binary classifier with size of training data 400  ...    0.63\n",
              "7  Naïve Bayes classifier with size of training d...  ...    0.80\n",
              "\n",
              "[8 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAx-aOfGOi9Y",
        "outputId": "73c6bf36-673e-454b-d84a-66453d4f597c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "from random import sample\n",
        "samples = [1, 10, 50, 100, 200, 400, 600, 700]\n",
        "\n",
        "classifiers={\"Binary classifier\":BinaryClassifier(20),\n",
        "             \"Naïve Bayes classifier\": NBClassifier()}\n",
        "\n",
        "use=[\"Binary classifier\",\"Naïve Bayes classifier\"]\n",
        "\n",
        "results = []\n",
        "sample_size = random.sample(samples,4)\n",
        "for s in sample_size:\n",
        "  for name,classifier in classifiers.items():\n",
        "    if name in use:\n",
        "      classifier.train(training_data[:s])\n",
        "      cn = ConfusionMatrix(get_predictions(classifier),get_goldstandards(classifier))\n",
        "      results.append((name+\"'s size of training data \"+str(s),cn.TP,cn.FP,cn.TN,cn.FN))\n",
        "             \n",
        "df = pd.DataFrame(results,columns= [\"Name of classifier and amount of training data\",\"True positives\",\"False Positives\",\"True Negatives\", \"False Negatives\"])\n",
        "display(df)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name of classifier and amount of training data</th>\n",
              "      <th>True positives</th>\n",
              "      <th>False Positives</th>\n",
              "      <th>True Negatives</th>\n",
              "      <th>False Negatives</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Binary classifier's size of training data 400</td>\n",
              "      <td>737</td>\n",
              "      <td>104</td>\n",
              "      <td>1544</td>\n",
              "      <td>414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naïve Bayes classifier's size of training data...</td>\n",
              "      <td>916</td>\n",
              "      <td>56</td>\n",
              "      <td>1592</td>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Binary classifier's size of training data 10</td>\n",
              "      <td>734</td>\n",
              "      <td>104</td>\n",
              "      <td>1544</td>\n",
              "      <td>417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Naïve Bayes classifier's size of training data 10</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1647</td>\n",
              "      <td>1141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Binary classifier's size of training data 700</td>\n",
              "      <td>737</td>\n",
              "      <td>111</td>\n",
              "      <td>1537</td>\n",
              "      <td>414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Naïve Bayes classifier's size of training data...</td>\n",
              "      <td>960</td>\n",
              "      <td>51</td>\n",
              "      <td>1597</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Binary classifier's size of training data 100</td>\n",
              "      <td>747</td>\n",
              "      <td>107</td>\n",
              "      <td>1541</td>\n",
              "      <td>404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Naïve Bayes classifier's size of training data...</td>\n",
              "      <td>188</td>\n",
              "      <td>2</td>\n",
              "      <td>1646</td>\n",
              "      <td>963</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Name of classifier and amount of training data  ...  False Negatives\n",
              "0      Binary classifier's size of training data 400  ...              414\n",
              "1  Naïve Bayes classifier's size of training data...  ...              235\n",
              "2       Binary classifier's size of training data 10  ...              417\n",
              "3  Naïve Bayes classifier's size of training data 10  ...             1141\n",
              "4      Binary classifier's size of training data 700  ...              414\n",
              "5  Naïve Bayes classifier's size of training data...  ...              191\n",
              "6      Binary classifier's size of training data 100  ...              404\n",
              "7  Naïve Bayes classifier's size of training data...  ...              963\n",
              "\n",
              "[8 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JPxfBdJNEJx"
      },
      "source": [
        "These experiments are designed to see the impact on training data on Binary and Naïve Bayes classifiers, the amount of training data is chosen randomly, from the random.sample() function as we can see above.\n",
        "\n",
        "If we look at the precision and the recall of the Binary classifier when a big amount of training data is imputed, the precision is quite high, but the recall is low. The reason for this is because for the precision, it is reducing the number of **False positives**, because it is not predicting our desired class(\"book\") as much, the goldstandard being the other class (\"dvd\"), however, as it is not predicting our desired class as much it is increasing the number of **False negatives** (goldstandard being \"book\", but predicition \"dvd\" which makes the recall smaller. If we imput less training data the opposite happens, the number of **False positives** increases and reduces the number of **False negatives**.\n",
        "\n",
        "For the Naïve Bayes classifier, we see that the amount of training data has a great impact on its accuracy, the lesser the training data the less accurate. This occurs because the Naïve Bayes classifier relies heavily on the probabilities of words occuring in a particular class document, with little training data, the Naïve Bayes classifier has a smaller vocabulary and can't tell wether a document belongs to the book or dvd class, unless the document contains words which appear in the Naïve Bayes classifier very limited vocabulary. For the precision and the recall, the reason the precision is so high when little training data is used is because the number of **False positives** is 0, because it has not predicted our desired class (\"book\") at any moment the goldstandard being the other class (\"dvd\"), still, the number of **False negatives** is reasonably high, meaning the recall is going to be very small. Unlike Binary classifiers, Naïve Bayes classifiers have high precision and high recall when lots of training data is used, because the number of **True positives** is increasing, which means that the more the training data, the more the classifier predicts correctly the desired class (in this case \"book)\n",
        "\n",
        "In conclusion, we can argue the more training data, the more precision and lesser recall, and the lesser the training data, the more recall and less precision. We have also concluded that the performance of the naïve bayes classifier has the best accuracy and final score, if it has trained from a big amount of training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34rdlS_iPov6",
        "outputId": "b0494a86-547f-4dcf-f074-e6160da2aeff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
        "##Running it before providing any answers shows that the questions have a word count of 388\n",
        "\n",
        "import io\n",
        "from nbformat import current\n",
        "\n",
        "filepath=\"/content/drive/My Drive/NLE Notebooks/NLE assignment/NLEassignment1.ipynb\"\n",
        "question_count=388\n",
        "\n",
        "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
        "    nb = current.read(f, 'json')\n",
        "\n",
        "word_count = 0\n",
        "for cell in nb.worksheets[0].cells:\n",
        "    if cell.cell_type == \"markdown\":\n",
        "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
        "print(\"Submission length is {}\".format(word_count-question_count))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submission length is 1530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtqCcG6wPsmf",
        "outputId": "dbbefc99-8e2a-484f-e8cf-08f3a0663c70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"The length of the coursework is {} words\".format(word_count-question_count))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the coursework is 1530 words\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}